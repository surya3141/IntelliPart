#!/usr/bin/env python3
"""
Production Conversational AI - Main Entry Point
Advanced AI assistant with Gemini, OpenAI, and Invertex AI integration
"""

import sys
import os
from pathlib import Path
from dataset_loader import load_all_parts


# Add the parent directory to the Python path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

def main():
    """Main function for production conversational AI"""
    print("üöÄ IntelliPart Production Conversational AI")
    print("=" * 60)
    print("ü§ñ AI-Powered Assistant ‚Ä¢ üîç Smart Search ‚Ä¢ üéØ Production Ready")
    print()
    
    # Available AI platforms
    ai_platforms = [
        {
            "name": "Production AI Assistant",
            "module": "production_ai_assistant",
            "description": "Multi-platform AI (Gemini, OpenAI, Invertex)",
            "features": ["Production Error Handling", "Context Management", "Visual Recognition"],
            "recommended": True
        },
        {
            "name": "Conversational Web App",
            "module": "conversational_web_app",
            "description": "Web-based conversational interface",
            "features": ["Web UI", "Real-time Chat", "Search Integration"],
            "recommended": False
        },
        {
            "name": "Lightweight AI Search",
            "module": "lightweight_ai_search",
            "description": "Fast TF-IDF based search",
            "features": ["Offline Search", "Fast Response", "No API Required"],
            "recommended": False
        }
    ]
    
    print("Available AI Platforms:")
    for i, platform in enumerate(ai_platforms, 1):
        status = "üåü RECOMMENDED" if platform["recommended"] else "üîß Available"
        features = " ‚Ä¢ ".join(platform["features"][:2])
        print(f"{i}. {platform['name']}")
        print(f"   {platform['description']} {status}")
        print(f"   Features: {features}")
        print()
    
    choice = input("Select AI platform (1-3) or press Enter for recommended: ").strip()
    
    if not choice:
        choice = "1"  # Default to production AI assistant
    
    try:
        choice_idx = int(choice) - 1
        if 0 <= choice_idx < len(ai_platforms):
            selected = ai_platforms[choice_idx]
        else:
            selected = ai_platforms[0]  # Default to first option
    except ValueError:
        selected = ai_platforms[0]  # Default to first option
    
    print(f"\nüîß Launching {selected['name']}...")
    
    try:
        if selected["module"] == "production_ai_assistant":
            print("ü§ñ Starting Production AI Assistant...")
            run_production_ai_assistant()
        elif selected["module"] == "conversational_web_app":
            print("üåê Starting Conversational Web App...")
            from conversational_web_app import app
            print("üåê Access the app at http://127.0.0.1:5000")
            app.run(debug=True, host='0.0.0.0', port=5000, use_reloader=False)
        elif selected["module"] == "lightweight_ai_search":
            print("‚ö° Starting Lightweight AI Search...")
            from lightweight_ai_search import interactive_ai_search as run_lightweight_search
            run_lightweight_search()
        else:
            print("üîÑ Falling back to web app...")
            from conversational_web_app import app
            print("üåê Access the app at http://127.0.0.1:5000")
            app.run(debug=True, use_reloader=False)
        
    except ImportError as e:
        print(f"‚ùå Import error: {e}")
        print("üîÑ Attempting fallback to web app...")
        try:
            from conversational_web_app import app
            print("üåê Starting fallback web app at http://127.0.0.1:5000")
            app.run(debug=True, use_reloader=False)
        except Exception as fallback_error:
            print(f"‚ùå Fallback failed: {fallback_error}")
            print("üìù Manual setup required - check requirements.txt")
    except Exception as e:
        print(f"‚ùå Launch failed: {e}")
        print("üîÑ Trying alternative launch method...")
        try:
            from conversational_web_app import app
            print("üåê Starting alternative web app at http://127.0.0.1:5000")
            app.run(debug=False, host='127.0.0.1', port=5000, use_reloader=False)
        except Exception as alt_error:
            print(f"‚ùå All launch methods failed: {alt_error}")

def run_production_ai_assistant():
    """Run the production AI assistant with interactive CLI"""
    try:
        from production_ai_assistant import ProductionAIOrchestrator, QueryContext
        
        print("\nü§ñ Production AI Assistant Ready!")
        print("=" * 50)
        print("Supported Platforms:")
        print("  ‚Ä¢ üîÆ Gemini Pro (Google)")
        print("  ‚Ä¢ üß† OpenAI GPT-4")
        print("  ‚Ä¢ üéØ Invertex AI (Vertex)")
        print()
        print("Commands:")
        print("  ‚Ä¢ Type your question about automotive parts")
        print("  ‚Ä¢ 'exit' or 'quit' to stop")
        print("  ‚Ä¢ 'help' for more options")
        print()
        
        # Initialize AI orchestrator
        orchestrator = ProductionAIOrchestrator()
        
        # Load all parts from the base dataset directory
        all_parts = load_all_parts()
        
        # Interactive conversation loop
        session_id = "cli_session_001"
        user_id = "production_user"
        
        while True:
            try:
                user_input = input("üîç Ask about parts: ").strip()
                
                if user_input.lower() in ['exit', 'quit', 'stop']:
                    print("üëã Goodbye! Thanks for using IntelliPart AI!")
                    break
                
                if user_input.lower() == 'help':
                    print("\nüìã Help:")
                    print("  ‚Ä¢ Search: 'Find brake pads for XUV700'")
                    print("  ‚Ä¢ Technical: 'What are the specs for part MP-001?'")
                    print("  ‚Ä¢ Compare: 'Compare engine parts from different suppliers'")
                    print("  ‚Ä¢ Analytics: 'Show me inventory insights'")
                    print()
                    continue
                
                if not user_input:
                    continue
                
                # Create query context
                context = QueryContext(
                    user_id=user_id,
                    session_id=session_id,
                    query_type="part_search",
                    priority="normal",
                    department="technical",
                    previous_queries=[]
                )
                
                # Process query
                print("ü§ñ Processing...")
                response = orchestrator.process_query(user_input, context)
                
                # Display response
                print(f"\nüí° {response.content}")
                
                if response.suggestions:
                    print(f"\nüìù Suggestions:")
                    for suggestion in response.suggestions[:3]:
                        print(f"  ‚Ä¢ {suggestion}")
                
                print(f"\n‚ö° Response time: {response.processing_time:.2f}s")
                print(f"üéØ Confidence: {response.confidence:.0%}")
                print(f"üîß Source: {response.source}")
                print()
                
            except KeyboardInterrupt:
                print("\nüëã Goodbye!")
                break
            except Exception as e:
                print(f"‚ùå Error: {e}")
                print("üîÑ Try rephrasing your question or type 'help'\n")
    
    except ImportError:
        print("‚ùå Production AI Assistant not available")
        print("üìã Install requirements: pip install -r requirements.txt")
        print("üîß Or use: python -m pip install google-generativeai openai")
    except Exception as e:
        print(f"‚ùå AI Assistant startup failed: {e}")

if __name__ == "__main__":
    main()
